# 4. Dimensionality reduction techniques

*This file describes the work and results of the fifth week a. k. a. "Dimensionality reduction techniques" of the IDOS2023 course.*

### 4.1 Graphical and numerical overview of data 

The data shows that the mean life expectancy at birth (*Life.Exp*) varies a lot, with a minimum of 49 years, a median of 74 years, and a maximum of 83 years, respectively. A high percentage of the population enjoys secondary education, both Female and Male (*Edu2.FM*), with a median of 93%. This is also well represented with the expected years of education (*Edu.Exp*) being around 13 years. The labour force participation rate (*Labo.FM*) shows a median of 75%. The representation of women in the parliament varies from none (min = 0) to a maximum of 57%. On average, every fifth member of a parliament is female. 

Many of the variables show some correlation. From the correlation matrix, we can see that *Life.Exp* and *Mat.Mor* have a strong relative correlation (-0.86). Also *Edu.Exp* and *Mat.Mor*, *Edu.Exp* and *Ado.Birth*, and *Life.Exp* and *Ado.Birth* are negatively correlated with -0.74, -0.7, and -0.73, respectively. On the other hand, *Edu.Exp* and *Life.Exp*, and *Mat.Mor* and *Ado.Birth* and strongly positively correlated witz 0.79 and 0.76, respectively. According to the black-and-white plots from ggpairs, all these relationships are significant. Looking at the distribution of our variables, we can see that *Edu.Exp* is the only normally distributed variable. *GNI* and *Mat.Mor* are strongly right skewed, and so are *Ado.Birth* and *Parli.F*, although to a lesser extent. Both *Labo.FM* and *Life.Exp* are left skewed.

```{r, message = FALSE, fig.height = 14, fig.width= 14}
# access all packages needed in this chunk
library(dplyr)
library(readr)
library(tibble)
library(corrplot)

# load in data
human <- read.csv(file='/home/ntriches/github_iods2023/IODS23/data/human.csv', header=TRUE)

# move the country names to rownames
human_ <- column_to_rownames(human, "Country")

# summary
summary(human_)

# visualize the 'human_' variables
plot_corr_humans <- human_ %>%
  ggpairs(progress = FALSE,
        upper = list(continuous = wrap("cor", size = 9)))
# plot corr_humans and adjust font size
plot_corr_humans + 
  theme(axis.text  = element_text(size = 20),
        strip.text = element_text(size = 20))

# compute the correlation matrix and visualize it with corrplot
cor_matrix <- cor(human_) %>%
  round(digits = 2)

# visualise the correlation matrix
# cl.cex = change font size of number-labels in colour-legend
# addCoef.col = add correlation value to circle, number.cex = adjust the font size of the number
plot_cor_matrix <- cor_matrix %>%
  corrplot(method="circle", addCoef.col = 0.5, type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 2,
           number.cex = 2, cl.cex = 2)


```

### 4.2 Principal component analysis (PCA)

Principal component analysis (PCA) helps us to summarise and visualise data with more than three dimensions. It is therefore a statistical approach that can be used to analyse high-dimensional data and capture the most important information from it. In that way, linear combinations of original predictions are changed into principal components that explain a large portion of the variation in a dataset.

Sources: 
https://www.datacamp.com/tutorial/pca-analysis-r
https://www.statology.org/principal-components-analysis-in-r/ 
https://www.datacamp.com/tutorial/pca-analysis-r
http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/

#### 4.2.1 PCA on non-standardised data

We can see that all values are very low in all principal components (*PC* 1-8).


"Perform principal component analysis (PCA) on the raw (non-standardized) human data. Show the variability captured by the principal components. Draw a biplot displaying the observations by the first two principal components (PC1 coordinate in x-axis, PC2 coordinate in y-axis), along with arrows representing the original variables."

```{r, message = FALSE}
# perform principal component analysis (with the SVD method)
pca_human <- prcomp(human_)
pca_human

#calculate total variance explained by each principal component
pca_human$sdev^2 / sum(pca_human$sdev^2)

# draw a biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))
?biplot

```



#### 4.2.2 PCA on standardised data 

We can see that the first principal component (*PC1*) has the highest values for *Edu.Exp* and *Life.Exp*, indicating that this PC describes the most variation in these variables. *PC2* shows the 

"Standardize the variables in the human data and repeat the above analysis. Interpret the results of both analysis (with and without standardizing). Are the results different? Why or why not? Include captions (brief descriptions) in your plots where you describe the results by using not just your variable names, but the actual phenomena they relate to. (0-4 points)"


```{r, message = FALSE}
# standardize the variables
human_std <- scale(human_)

# print out summaries of the standardized variables
summary(human_std)

# perform principal component analysis (with the SVD method)
pca_human_std <- prcomp(human_std)
pca_human_std

#calculate total variance explained by each principal component
pca_human$sdev^2 / sum(pca_human$sdev^2)

# draw a biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))
?biplot

```




"Give your personal interpretations of the first two principal component dimensions based on the biplot drawn after PCA on the standardized human data. (0-2 points)"


### 4.3 Multipe Correspondence Analysis (MCA)




"The tea data comes from the FactoMineR package and it is measured with a questionnaire on tea: 300 individuals were asked how they drink tea (18 questions) and what are their product's perception (12 questions). In addition, some personal details were asked (4 questions).

Load the tea dataset and convert its character variables to factors:

tea <- read.csv("https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/tea.csv", stringsAsFactors = TRUE)

Explore the data briefly: look at the structure and the dimensions of the data. Use View(tea) to browse its contents, and visualize the data.

Use Multiple Correspondence Analysis (MCA) on the tea data (or on just certain columns of the data, it is up to you!). Interpret the results of the MCA and draw at least the variable biplot of the analysis. You can also explore other plotting options for MCA. Comment on the output of the plots. (0-4 points)"


Source: http://sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/114-mca-multiple-correspondence-analysis-in-r-essentials
